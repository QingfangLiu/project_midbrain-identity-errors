{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fcbad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b42b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/Users/qingfangliu/Library/CloudStorage/Dropbox/KahntLab/Project_SPEEDTMS/Analysis'\n",
    "external = '/Volumes/QF10TB/SPEEDTMS_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfdd9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subject information\n",
    "sub_info_file = os.path.join(parent_dir, 'SubInfo', 'SubjectConds.XLSX')\n",
    "sub_info = pd.read_excel(sub_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e91115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract subject indices and exclusion information\n",
    "subs = sub_info['Sub']\n",
    "excluded = sub_info['Excluded']\n",
    "subs = subs[excluded == 0]  # Keep only subjects not excluded\n",
    "nsubs = len(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec44cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavioral data\n",
    "# Assuming Alld.mat is a standard MATLAB .mat file (not v7.3 HDF5 format)\n",
    "alld_path = os.path.join(external, 'Behavior', 'Alld.mat')\n",
    "alld = scipy.io.loadmat(alld_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85439e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'Outcome_pseudoconcat_Nz'\n",
    "decodetype = 'LOOCV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6074ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info to prepare data loading\n",
    "nruns = 3\n",
    "nSess = 2\n",
    "nallruns = nruns * nSess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bcd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mask path and name\n",
    "maskmap = os.path.join(parent_dir, 'Masks', 'Group_mask.nii')\n",
    "maskname = 'WB'\n",
    "\n",
    "# Load the mask NIfTI file\n",
    "mask_img = nib.load(maskmap)\n",
    "mask_data = mask_img.get_fdata()\n",
    "\n",
    "# Get the shape (dimensions)\n",
    "sz = mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed022232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 95, 79)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bf34a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the linear indices of non-zero voxels (in flattened array)\n",
    "lin_index = np.flatnonzero(mask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4cec156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203528,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dda7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_use = 'beta'\n",
    "dat_scale = 'raw'\n",
    "rget = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35f52a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to do searchlight\n",
    "# based on which mask map to use\n",
    "\n",
    "# define reference voxel\n",
    "ref_vox = np.round(np.array(sz) / 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f6e127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 48, 40])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f998226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D coordinate grid\n",
    "MX, MY, MZ = np.meshgrid(\n",
    "    np.arange(1, sz[0]+1),  # MATLAB is 1-indexed, so add 1\n",
    "    np.arange(1, sz[1]+1),\n",
    "    np.arange(1, sz[2]+1),\n",
    "    indexing='ij'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37686718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Euclidean distance from each voxel to the reference voxel\n",
    "radii = np.sqrt((MX - ref_vox[0])**2 + (MY - ref_vox[1])**2 + (MZ - ref_vox[2])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7370adb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 95, 79)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c1f632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prototype sphere index for voxels within `rget` radius\n",
    "ref_index = np.ravel_multi_index(tuple(ref_vox - 1), sz)  # adjust for 0-indexing\n",
    "radius_index = np.flatnonzero(radii < rget) - ref_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8b80cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radius_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "016fbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of searchlights (i.e., number of voxels in the mask)\n",
    "nvox = len(lin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3766546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversion map: 3D volume with consecutive indices at mask locations\n",
    "linindexconv = np.zeros(sz, dtype=int)\n",
    "linindexconv_flat = linindexconv.ravel()\n",
    "linindexconv_flat[lin_index] = np.arange(1, len(lin_index) + 1)\n",
    "linindexconv = linindexconv_flat.reshape(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72207ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub2\n"
     ]
    }
   ],
   "source": [
    "# looping through subjects\n",
    "# this analysis is done within each subject\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Assume Subs is a pandas Series or list of subject numbers\n",
    "subno = f'Sub{subs[i]}'  # Create subject string\n",
    "print(subno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0588f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to subject decoding results\n",
    "subjpath = os.path.join(external, 'Decoding_Searchlight_python', subno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49d6737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub2 - beta - raw\n"
     ]
    }
   ],
   "source": [
    "# Construct result path\n",
    "res_path = os.path.join(subjpath, modelname, maskname, dat_use, dat_scale, f'r{rget}')\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "\n",
    "# Print summary info\n",
    "print(f'{subno} - {dat_use} - {dat_scale}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "270dd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load data of beta estimates for decoding\n",
    "\n",
    "# Prepare to organize betas into runs\n",
    "data = [None] * nallruns\n",
    "Labels = [None] * nallruns\n",
    "nconds = 3\n",
    "rctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f7a40cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52bc61f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76d2b331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data organization: Sub2-r1\n",
      "Data organization: Sub2-r2\n",
      "Data organization: Sub2-r3\n",
      "Data organization: Sub2-r4\n",
      "Data organization: Sub2-r5\n",
      "Data organization: Sub2-r6\n"
     ]
    }
   ],
   "source": [
    "for ss in range(nSess):\n",
    "    for r in range(nruns):\n",
    "        print(f'Data organization: {subno}-r{rctr+1}')\n",
    "        temp = np.zeros((nconds,nvox))  \n",
    "        \n",
    "        for n in range(nconds):\n",
    "            bidx = n + 3 * rctr + 1\n",
    "            bname = os.path.join(external, 'Decoding_GLM', subno, 'fxMultivariate', modelname, f'beta_{bidx:04d}.nii')\n",
    "            vol = nib.load(bname).get_fdata()\n",
    "            temp[n,:] = vol.flatten()[lin_index] # extract ROI voxel data\n",
    "            \n",
    "        data[rctr] = temp\n",
    "        Labels[rctr] = np.arange(1, nconds+1)\n",
    "        rctr += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "532dae01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[            nan,             nan,             nan, ...,\n",
       "          7.07192659e-01,  1.26317009e-01, -1.57458365e-01],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "          4.76203799e-01, -1.24924707e+00, -4.51054802e-04],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "          7.43021131e-01, -5.25924027e-01, -5.68005443e-01]]),\n",
       " array([[        nan,         nan,         nan, ..., -0.21465586,\n",
       "         -1.04216063, -1.01983523],\n",
       "        [        nan,         nan,         nan, ..., -0.35943496,\n",
       "         -1.30116093, -0.95837456],\n",
       "        [        nan,         nan,         nan, ...,  0.01606934,\n",
       "          0.18507093, -0.13777131]]),\n",
       " array([[        nan,         nan,         nan, ...,  0.49997833,\n",
       "         -0.75954312, -0.64725244],\n",
       "        [        nan,         nan,         nan, ..., -0.18594971,\n",
       "         -1.01889813, -1.01164329],\n",
       "        [        nan,         nan,         nan, ...,  0.24840146,\n",
       "         -0.27893299, -0.01248497]]),\n",
       " array([[        nan,         nan,         nan, ..., -0.41689119,\n",
       "         -0.77434683, -1.185624  ],\n",
       "        [        nan,         nan,         nan, ..., -1.02187479,\n",
       "         -0.36869469, -0.56988287],\n",
       "        [        nan,         nan,         nan, ..., -0.79923761,\n",
       "         -0.03500925, -0.99328995]]),\n",
       " array([[        nan,         nan,         nan, ..., -0.34849307,\n",
       "         -0.55422646, -0.83650762],\n",
       "        [        nan,         nan,         nan, ..., -0.26605758,\n",
       "          0.25117317, -0.44995439],\n",
       "        [        nan,         nan,         nan, ...,  0.11227481,\n",
       "         -0.50225335, -1.12339413]]),\n",
       " array([[        nan,         nan,         nan, ...,  0.71017414,\n",
       "         -0.3293919 ,  0.05341902],\n",
       "        [        nan,         nan,         nan, ...,  0.53090233,\n",
       "         -0.18830486, -0.64446068],\n",
       "        [        nan,         nan,         nan, ...,  0.01756616,\n",
       "         -0.28080624, -1.38878179]])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6df930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3]),\n",
       " array([1, 2, 3]),\n",
       " array([1, 2, 3]),\n",
       " array([1, 2, 3]),\n",
       " array([1, 2, 3]),\n",
       " array([1, 2, 3])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02dcef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultvol_vol = np.zeros(sz)  # volume to save decoding accuracy\n",
    "temp_sl_res = np.zeros(nvox)  # vector to save searchlight results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c163d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchlight_single_voxel(cnt):\n",
    "    if cnt % 1000 == 0:\n",
    "        print(f'Searchlight - V: {cnt}/{nvox}')\n",
    "        \n",
    "    # move prototype sphere to position of current voxel\n",
    "    indexindex = radius_index + lin_index[cnt]\n",
    "    \n",
    "    # eliminate indices outside brain mask\n",
    "    Useindex = np.intersect1d(lin_index, indexindex)\n",
    "    \n",
    "    # Map to data indices\n",
    "    dat_index = linindexconv.flatten()[Useindex]\n",
    "\n",
    "    runvec = np.arange(nallruns)  # 0-indexed in Python\n",
    "    accvals = np.zeros(len(runvec))\n",
    "    \n",
    "    for idx, r in enumerate(runvec):\n",
    "        rtrain = runvec[runvec != r]  # Leave-one-run-out\n",
    "        rtest = r\n",
    "\n",
    "        vectors_train = np.vstack([data[t][:, dat_index] for t in rtrain])\n",
    "        labels_train = np.hstack([Labels[t] for t in rtrain])\n",
    "\n",
    "        vectors_test = data[rtest][:, dat_index]\n",
    "        labels_test = Labels[rtest]\n",
    "        \n",
    "        # remove samples with NANs\n",
    "        train_nan_mask = ~np.isnan(vectors_train).any(axis=1)\n",
    "        test_nan_mask = ~np.isnan(vectors_test).any(axis=1)\n",
    "\n",
    "        vectors_train = vectors_train[train_nan_mask]\n",
    "        labels_train = labels_train[train_nan_mask]\n",
    "\n",
    "        vectors_test = vectors_test[test_nan_mask]\n",
    "        labels_test = labels_test[test_nan_mask]\n",
    "        \n",
    "        # Only proceed if there is enough data after cleaning\n",
    "        if len(labels_train) == 0 or len(labels_test) == 0:\n",
    "            accvals[idx] = 33.33  # assume chance level\n",
    "            continue\n",
    "\n",
    "        # Train and test SVM\n",
    "        clf = SVC(kernel='linear', C=0.0001)\n",
    "        clf.fit(vectors_train, labels_train)\n",
    "        pred_label = clf.predict(vectors_test)\n",
    "\n",
    "        accvals[idx] = accuracy_score(labels_test, pred_label) * 100\n",
    "\n",
    "    outcome = np.mean(accvals)  # average accuracy\n",
    "    return outcome - 33.33  # subtract chance level (3 classes: 33.33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f29869a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 203528 is out of bounds for axis 1 with size 203528",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/qingfangliu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/Users/qingfangliu/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/qingfangliu/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/qingfangliu/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/var/folders/w1/6bg1f9b95nv9ffmqmk5plvb80000gn/T/ipykernel_27968/2431174247.py\", line 21, in searchlight_single_voxel\n  File \"/var/folders/w1/6bg1f9b95nv9ffmqmk5plvb80000gn/T/ipykernel_27968/2431174247.py\", line 21, in <listcomp>\n  File \"/Users/qingfangliu/opt/anaconda3/lib/python3.9/site-packages/numpy/core/memmap.py\", line 335, in __getitem__\n    res = super().__getitem__(index)\nIndexError: index 203528 is out of bounds for axis 1 with size 203528\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m temp_sl_res \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearchlight_single_voxel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcnt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnvox\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m temp_sl_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(temp_sl_res)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 203528 is out of bounds for axis 1 with size 203528"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "temp_sl_res = Parallel(n_jobs=-1)(delayed(searchlight_single_voxel)(cnt) for cnt in range(nvox))\n",
    "temp_sl_res = np.array(temp_sl_res)  # back to numpy array\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the searchlight results back into the full 3D space\n",
    "resultvol_vol = np.zeros(sz)\n",
    "resultvol_vol_flat = resultvol_vol.flatten()\n",
    "resultvol_vol_flat[lin_index] = temp_sl_res\n",
    "resultvol_vol = resultvol_vol_flat.reshape(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a header (affine and header info) from an existing beta file\n",
    "ref_img = nib.load(bname)  # bname from your last loaded beta\n",
    "\n",
    "# Create a new NIfTI image with the result data and original affine/header\n",
    "result_img = nib.Nifti1Image(resultvol_vol, affine=ref_img.affine, header=ref_img.header)\n",
    "\n",
    "# Define the output file path\n",
    "Resultname = f'Acc_{subno}_{decodetype}.nii'\n",
    "result_path = os.path.join(res_path, Resultname)\n",
    "\n",
    "# Save the NIfTI file\n",
    "nib.save(result_img, result_path)\n",
    "\n",
    "print(f\"Result saved to {result_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
